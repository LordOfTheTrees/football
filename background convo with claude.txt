Great question! Yes, you can use regression coefficients to adjust for these inflation effects before averaging. Here's a solid approach:
The Basic Method

Run a regression model with Y1 performance as your dependent variable and include:

Draft year (as a continuous variable or dummy variables)
Draft slot (position selected)
Interaction term if you suspect the inflation varies by draft slot


Extract the year coefficient(s) - this captures the average increase in performance per year due to offensive inflation
Adjust historical performances by subtracting out the inflation effect:

Adjusted Performance = Raw Performance - (Year Coefficient × Years Since Baseline)
Choose a baseline year (like 2000 or 2024) to normalize to


Then calculate averages by draft slot using the adjusted values

Example Calculation
Say your regression shows Y1 passing yards increase by 50 yards/year on average:

A QB drafted in 2005 with 3,200 yards would adjust to: 3,200 - (50 × 5) = 2,950 yards (normalized to 2000)
A QB drafted in 2015 with 3,500 yards: 3,500 - (50 × 15) = 2,750 yards (normalized to 2000)

Now you can fairly average these adjusted values across all QBs at draft slot #1, #10, etc.
Important Considerations

Non-linear effects: Era changes might not be perfectly linear (rule changes in 2004, 2011, etc.). Consider using year dummy variables or splines
Sample size: Early draft picks play more in Y1, so they might show different inflation patterns
Multiple metrics: Adjust completion %, TD rate, INT rate separately as they've inflated at different rates

Would you like help setting up the specific regression model for your dataset?RetryALet's just talk philosophically for now. To determine how different qb slots are treated, I'm thinking of doing a cluster analysis around starts and draft position. Thoughts?That's an interesting approach! Let me think through the philosophy of what you're trying to capture.
What Cluster Analysis Would Reveal
Clustering on starts + draft position would naturally segment QBs into groups like:

"Immediate starters" (high draft picks, lots of Y1 starts)
"Development projects" (mid-round picks, few Y1 starts)
"Situational/backup" (late picks, sporadic starts)

This captures organizational behavior - how teams treat different draft slots.
The Philosophical Question
But here's the key consideration: Are you trying to understand treatment patterns, or are you trying to control for opportunity when evaluating talent?
If your ultimate goal is adjusting for "draft slot inflation" to assess QB performance, you might have a selection bias problem:

High picks get more starts because teams invested in them
But they also get more starts because they were better prospects
Clustering captures both simultaneously

The clusters would show you what happened, but when you're trying to determine "average Y1 performance for a given draft slot," you're fighting against the fact that starts themselves are endogenous to the evaluation.
Alternative Framing
You could think about it as:

Cluster analysis → "What are the typical career paths by draft capital?"
Per-start or rate-based metrics → "Given opportunity, how did they perform?"

Maybe the more direct approach is: adjust for inflation as we discussed, then look at draft slot performance while controlling for opportunity (attempts, starts) as a separate variable rather than clustering on it?
What's your end goal - understanding team behavior patterns, or isolating QB talent evaluation across eras?RetryAFor that it's more about how they are treated. I understand the dual cause problem.I'm envisioning a development height style chart where we can plot certain qbs against the average of their slot, where above a certain profile, they were paid, and below they weren't. Does that sound like a functional visualization technique?Yes, that sounds like a very functional visualization! Let me think through what makes this work:
Why This Works
You're essentially creating a "market value threshold" visualization that shows:

X-axis: Draft slot (or cluster group)
Y-axis: Y1 performance metric(s) - inflation-adjusted
Reference line: Average performance for that slot/cluster
Color/symbol coding: Whether they got paid (2nd contract, extension, etc.)

The power is in showing the decision boundary - where does performance cross from "replacement level" to "franchise QB" treatment?
What You'd Learn

Does the threshold vary by draft slot?

Do teams give 1st rounders more rope (lower bar for getting paid)?
Do late-round picks need to vastly outperform to earn a contract?


Outlier identification

QBs paid below the line (overvalued by draft capital)
QBs unpaid above the line (missed opportunities)


Era effects

Has the "performance-to-payment" threshold tightened over time as teams get more analytical?



Visualization Suggestion
Consider a small multiples approach - separate panel for each draft slot range or cluster, making the within-group patterns clearer. Or a single scatter with vertical reference lines separating draft slot ranges and horizontal lines showing average performance within each range.
The "height chart" metaphor works perfectly - like those "you must be this tall to ride" signs at amusement parks, but for QB contracts.
What performance metrics are you thinking - composite score, or something specific like adjusted yards/attempt?RetryANo, I'm envisioning x axis as year since drafting, y metric is the most correlated performance metric/s to getting paid, and the nonlinear chart shows the progress of 1 qb relative to the averageAh, now I see it - that's a much more elegant visualization!
The Development Trajectory Chart
X-axis: Years since drafted (0, 1, 2, 3, 4...)
Y-axis: Performance metric(s) most predictive of getting paid
Lines:

Individual QB's actual trajectory (solid line)
Average trajectory for their draft slot (reference line, maybe shaded confidence interval)
Potentially a "payment threshold" line

This captures the development narrative - you can see:

Does this QB start above/below their slot average?
Do they improve faster or slower than peers?
At what point do they cross the "gets paid" threshold?
Did they get paid before or after reaching that threshold?

Why This Is Better
It's fundamentally about rate of development and trajectory shape, not just static Y1 performance. A QB who starts slow but improves rapidly tells a different story than one who plateaus early.
The "height chart" metaphor now makes even more sense - like those growth charts pediatricians use with percentile curves.
Key Question
For the reference lines: Are you showing one chart per QB (comparing them to their specific draft slot average), or overlaying multiple QBs from the same slot to see the distribution of trajectories?
And do you already have a sense of which metrics correlate most strongly with getting paid - is it volume stats, efficiency, or wins?RetryANot sure yet. But I would have to take the most predictive "individual" performance factor/s. Obviously understanding that passing requires someone to catch, etc...Right, that's the perpetual QB evaluation problem - disentangling individual contribution from system/talent around them.
Thinking Through Metric Selection
You're looking for metrics that are:

Predictive of payment decisions (what GMs actually value)
Maximally attributable to the QB (less context-dependent)

These two don't always align! GMs might pay based on volume stats (yards, TDs) even if efficiency metrics are more "QB-pure."
Philosophical Approaches
Empirical approach: Run a logistic regression - "got paid" as dependent variable, test which Y1-Y4 metrics have strongest predictive power. Let the data tell you what teams actually reward.
Analytical approach: Use metrics designed to isolate QB contribution:

Completion % over expectation (CPOE)
EPA per play
Pressure-to-sack rate (decision-making)
Time to throw (processing speed)

But here's the tension: Next-gen stats might be more "pure" but weren't available pre-2016ish, so you lose historical comparability for your inflation adjustment.
Hybrid Solution?
You could identify what traditional stats (available since 2000) correlate most strongly with getting paid, then validate on a subset with advanced metrics to ensure they're actually capturing QB skill rather than circumstance.
Or accept that you're modeling "what gets rewarded" rather than "what's most deserved" - which might be the more honest framing for understanding market behavior anyway.
Where's your instinct leaning - toward empirical discovery or theory-driven metric selection?RetryAHow should I think about years. I feel like I need to offset each year as x, x+1, etc... but the decision to pay factors a different amount of information each time depending on the amount of time they've played for before signing.Excellent point - you've identified a critical structural issue.
The Problem
Payment decisions aren't made at fixed intervals. They're made:

After Year 3 for high picks (5th year option decision)
After Year 4 for most (rookie contract expiration)
Sometimes earlier (early extensions for stars)
Sometimes later (franchise tags, prove-it deals)

So when a team decides to pay in Year 3, they have 3 years of data. When they wait until Year 5, they have 5 years. The information set varies.
Potential Approaches
1. Time-to-event modeling (survival analysis)

Treat "getting paid" as an event that can happen any year
Model: What performance trajectory leads to payment at Year X?
Captures that some QBs get paid early, others late, others never

2. Fixed decision windows

Analyze separately: "Who got extended after Year 3?" vs "Who got paid after Year 4?"
Different performance profiles might predict each
Acknowledges these are fundamentally different decisions

3. Cumulative performance view

X-axis: Career games/starts (not years)
Y-axis: Cumulative or rolling average performance
Payment happens at different X-values for different QBs
Captures that some 1st rounders get 40 starts by Year 3, while others take 5 years

4. Weighted recent performance

Teams likely weight recent years more heavily
Model payment as f(Year N performance, Year N-1, Year N-2...) with decay weights
Run this at each potential decision point

Which framing feels closest to the reality you're trying to model?RetryAProbably weighted recent performance, but survivability feels interesting. Let's explore those. Averages feel wrong since recent years are far more predictive than older ones. Maybe we can benchmark years by years before signage? That might allow us to back into observed recency rating?Oh, that's clever - working backwards from the signing date to discover the implicit weighting!
Reverse Engineering Recency Bias
Instead of assuming a decay function, let it emerge from the data:
Structure:

For each QB who got paid, anchor at their signing year as t=0
Look backwards: t-1, t-2, t-3, t-4 (years before signing)
Run regression: P(got paid) ~ β₁(perf at t-1) + β₂(perf at t-2) + β₃(perf at t-3)...

The relative magnitude of coefficients reveals how teams actually weight different years. If β₁ >> β₂ >> β₃, that's strong recency bias. If they're similar, teams consider full body of work equally.
Why This Works Better

Aligns with decision-making reality: Teams evaluate "what have you done lately?"
Controls for varying contract timing: Whether paid after Year 3 or Year 5, you're measuring the same lookback window
Handles sparse early careers: A QB with few Y1 starts but strong Y2-Y3 won't be penalized

Combining with Survival Analysis
You could layer this:

Survival model: What determines when a QB gets paid (or doesn't)?
Coefficient analysis: What performance history predicts payment at each timepoint?

The survival framework handles the "some get paid early, some late, some never" problem, while the backwards-looking window reveals what teams actually value.
Practical Question
For QBs who didn't get paid - do you:

Exclude them (only model among those who got paid)?
Include them with a censored event at end of rookie deal?
Code their "signing year" as when they left the team?

The philosophical choice here affects interpretation significantly.RetryAWhat would he the rationales to both the first 2 approaches. My intuition was to leave them out, but that migght give a major asterisk to the analysis.Great instinct - let's think through the implications of each:
Approach 1: Only Include QBs Who Got Paid
Rationale:

You're modeling "conditional on being good enough, what performance pattern leads to payment?"
Cleaner interpretation: "Among franchise QBs, teams weight the most recent year X times more than two years ago"
Avoids contamination from QBs who failed for non-performance reasons (injuries, off-field, scheme fit)

The Asterisk:

You're only learning about the upper tail of QB outcomes
Can't identify the payment threshold itself - just relative preferences above it
Selection bias: The coefficients might be different if you could see the full distribution

Approach 2: Include Non-Paid QBs (Censored)
Rationale:

Models the complete decision space: "What separates franchise QBs from replacements?"
Survival analysis is designed exactly for this - censored observations (didn't get paid yet or ever) are informative
You can identify the threshold effect: "You need at least X performance in recent years to even be considered"

The Challenge:

Non-paid QBs are heterogeneous: busts, backups who never got chances, late bloomers who left
"Didn't get paid" could mean "clearly not good enough" OR "didn't get enough opportunity to show it"

The Philosophical Distinction

Approach 1: "What do teams value when building a franchise around a QB?"
Approach 2: "What separates franchise QBs from everyone else?"

My Take
I'd argue Approach 2 with survival analysis is more robust because:

The censoring framework handles uncertainty (was cut vs. still developing)
You get both the threshold AND the preferences above it
More generalizable - you can predict for current QBs whether they're on track for payment

But you'd want to be careful about opportunity bias - control for games started or attempts in the model so you're not penalizing QBs who simply didn't play.
Does the goal feel more like "understand team preferences" (→ Approach 1) or "predict who gets paid" (→ Approach 2)?RetryAExplain the survival modeling more carefully. It feels imprecise. Your out of consideration is the off the team right? What would the visual of success and of failure look like then?You're right to push back - let me be more precise about what survival analysis would actually mean here.
Survival Analysis Framework
The "event": Getting paid (2nd contract, extension, etc.)
Time dimension: Years since drafted
Censoring: Still on rookie deal when data collection ends, OR left team without getting paid
The Core Problem You've Identified
When a QB leaves without getting paid, that's not really censoring in the traditional sense - it's more like a competing event. They didn't "not get paid yet" - they definitively failed to reach the threshold.
True censoring would be: "QB is in Year 3 of rookie deal, still in consideration, we just don't know the outcome yet."
What The Visuals Would Look Like
Success trajectory:

X-axis: Years since drafted (0-5+)
Y-axis: Performance metric
Line trends upward or stays strong
Event marker at year of signing (maybe Year 3 or 4)
Shaded region showing "average for draft slot"

Failure trajectory:

Same axes
Line trends downward or stays below threshold
Termination marker when cut/not re-signed (maybe Year 4 or 5)
Falls below the payment threshold band

The Real Question
Survival analysis works best when you're modeling time until inevitable event with some observations incomplete. But here:

Some QBs will get paid (event happens)
Some QBs will never get paid (event cannot happen)
Some QBs are still uncertain (true censoring)

This is actually closer to a competing risks model:

Risk 1: Get paid
Risk 2: Get cut/leave without payment
Censored: Still in consideration

Alternative Framing
Maybe survival analysis is the wrong metaphor entirely. Instead:
Discrete-time logistic regression at each decision point:

Year 3: P(get 5th year option) given performance in Y1-Y3
Year 4: P(get extension) given performance in Y1-Y4
Year 5: P(get second contract) given full rookie deal performance

Each year is a separate binary outcome, and you model what predicts "yes" at each stage.
Does that feel more precise? Or are we overcomplicating what might be simpler: just comparing paid vs. unpaid trajectories directly?RetryADiscrete time logistic regression feels the most precise, but the least helpful for modeling trajectories. How could we combine them back into a single chart afterwards?Good question - you want the precision of discrete-time modeling but the interpretability of trajectory visualization. Here's how to bridge them:
Building The Combined Visualization
Step 1: Run discrete-time models separately

Model₃: P(paid | performance Y1-Y3)
Model₄: P(paid | performance Y1-Y4)
Model₅: P(paid | performance Y1-Y5)

Extract the coefficients to understand recency weighting at each decision point.
Step 2: Create predicted probability bands
For the average QB at each draft slot, calculate:

At Year 3: probability of payment based on typical Y1-Y3 trajectory
At Year 4: probability based on typical Y1-Y4 trajectory
At Year 5: probability based on typical Y1-Y5 trajectory

Step 3: Visualize as threshold zones
The chart would show:

X-axis: Years since drafted
Y-axis: Performance metric
Background shading: Probability zones

Dark green: >70% got paid (above trajectory)
Light green: 40-70% got paid (borderline)
Yellow: 10-40% (struggling)
Red: <10% (likely done)



Step 4: Overlay individual QB trajectory
Plot a specific QB's year-by-year performance as a line cutting through these zones. You can see:

"Started in yellow zone, improved into green by Year 3" → Got paid early
"Stayed in green but dipped to yellow in Year 4" → Didn't get paid
"Climbed from red to light green" → Late bloomer who earned it

The Key Insight
The zones dynamically shift as time progresses because teams have more information. The Year 3 "safe zone" might require higher performance than Year 4's "safe zone" because teams are less certain early.
Alternative: Probability Trajectory
Instead of performance on Y-axis, you could show:

Y-axis: P(gets paid) based on performance to date
Individual QB's probability evolves over time based on their actual performance fed through your models

This would literally show "at each year, what were their chances?"
Would you want performance metric (shows what they did) or probability (shows implication of what they did) on the Y-axis?RetryASo it's just 3-4 color bands on the graph? How would that look when the same year has different weights based on the current year?Ah, you've hit the visualization challenge - the bands would need to change shape as you move along the X-axis because the weighting system evolves.
The Dynamic Band Problem
At Year 3 decision point:

Y1 performance has weight β₁⁽³⁾
Y2 performance has weight β₂⁽³⁾
Y3 performance has weight β₃⁽³⁾

At Year 4 decision point:

Y1 performance now has weight β₁⁽⁴⁾ (probably lower)
Y2 performance has weight β₂⁽⁴⁾ (lower than before)
Y3 performance has weight β₃⁽⁴⁾ (still relevant)
Y4 performance has weight β₄⁽⁴⁾ (most important)

So a QB's Y2 performance matters differently depending on whether we're evaluating them in Year 3 vs Year 4.
Visualization Options
Option A: Segmented bands
The chart has vertical sections at each decision year:

Years 1-3 zone (evaluated at Y3): Bands based on Model₃
Year 4 zone: Bands recalculate based on Model₄
Year 5 zone: Bands recalculate based on Model₅

The individual QB trajectory line moves through these sections, and you can see if they cross into "payment zone" at any decision point.
Drawback: Visually jarring - bands literally shift/jump at Year 3→4 boundary
Option B: Rolling probability overlay

Plot raw performance trajectory (no bands)
Add points or markers at each decision year showing P(gets paid) at that moment
Size/color of marker indicates probability tier
Connect markers to show how their "draft stock" evolved

Option C: Small multiples
Three separate mini-charts:

"Year 3 Decision": Shows Y1-Y3 performance with Year-3-weighted bands
"Year 4 Decision": Shows Y1-Y4 performance with Year-4-weighted bands
"Year 5 Decision": Shows Y1-Y5 performance with Year-5-weighted bands

You see how the same QB looks different through each lens.
Option D: Animated/interactive
As you slide along the X-axis, the bands morph to reflect the current decision point's weighting scheme. Probably too complex for static presentation.
My Instinct
Option B feels cleanest - you're not trying to show probability bands continuously, but rather showing the QB's performance trajectory with discrete "evaluation moments" overlaid. It acknowledges that payment decisions happen at specific points, not continuously.
What's your presentation context - is this for exploratory analysis (interactive is fine) or communicating findings (needs to be immediately interpretable)?RetryANo I want one chart. Let's explore how size and color might work together to Visualize this. Perhaps the size is the weight, color is the performance relative to the expectation? What about some other ideas?Ooh, interesting - using visual dimensions to encode multiple data layers. Let me explore some approaches:
Option 1: Size = Weight, Color = Performance
For each year-point on the trajectory:

Dot size: How much that year's performance matters to current decision (grows/shrinks as time passes)
Color: Performance relative to draft slot expectation (green = above, red = below)

What you'd see:

Year 1 dot starts large (matters for Y3 decision), then shrinks as it becomes ancient history
Year 4 dot is HUGE when evaluating at Year 4, represents most of their "value"
Color pattern shows if they improved (red→yellow→green) or declined

Drawback: Dots overlap/cluster, hard to read
Option 2: Line Thickness = Recency Weight
The trajectory line itself changes thickness:

Between Y1-Y2: Line thickness represents how much Y1 matters at that point in time
Between Y3-Y4: Line is thickest because recent performance matters most
As you look back from any decision point, line fades/thins toward the past

Color: Performance tier (red/yellow/green zones)
What you'd see: A trajectory that's literally visually weighted - recent performance jumps out at you
Option 3: Heatmap Background
Background cells (year × performance level):

Color intensity: Probability of getting paid given that performance in that year
The trajectory line cuts through this heatmap

What you'd see:

Dark green cells at Y3-Y4 in high performance = "hot zone" for getting paid
Pale cells at Y1 even with good performance = "doesn't matter much yet"
QB trajectory shows which zones they passed through

Option 4: Dual Encoding on Points
Each year gets a marker with:

Ring/outer glow size: Weight in payment decision
Inner fill color: Absolute performance level
Position (Y-axis): The actual metric value

Connect with line to show trajectory.
Example: Y4 would have a HUGE glowing ring (high weight) with green center (good performance) placed high on Y-axis.
Option 5: Ribbon/Band Width
Instead of a line, show a ribbon:

Ribbon width: Confidence interval or importance weight
Ribbon color gradient: Performance relative to expectation
Vertical position: Actual metric value

Recent years = fat ribbon (high weight), old years = thin ribbon (fading importance)
My Favorite: Option 3 (Heatmap)
Why: It shows the decision landscape that QBs navigate through. The heatmap is static (derived from your models), the QB trajectory is dynamic. You immediately see:

"This QB stayed in the green zone" = got paid
"This QB climbed from red to yellow but never hit green" = didn't make it
"This QB hit green early then crashed" = what happened?

Which approach resonates with your mental model?RetryAYeah I like the heat map option too. And we can plot line & points of when others were paid relative to the norm. I guess my worry there is it implicitly implies that being paid early is bad? Help me think through thisExcellent catch - you've identified a subtle but important interpretive problem.
The Ambiguity of Early Payment
Early payment could mean:

Scenario A: QB is crushing it, obviously franchise-caliber → smart early investment
Scenario B: Team is desperate/impatient, overpaying based on limited sample → risky bet

Late payment could mean:

Scenario C: QB took time to develop but earned it → patient evaluation paid off
Scenario D: QB was borderline, team hesitated → uncertainty/lack of conviction

The heatmap showing "typical payment timing" doesn't distinguish between these.
Visual Solutions
Option 1: Annotate payment outcome

Line shows trajectory through heatmap
Payment marker includes icon or label: ✓ (worked out) vs ✗ (busted/didn't pan out)
Now early payment in green zone = smart, early payment in yellow zone = risky gamble

Option 2: Dual heatmaps side-by-side

Left: "When QBs typically got paid"
Right: "Payment success rate" (% who met contract value/expectations)
Same trajectory plots on both, reveals if early payers succeeded

Option 3: Add a trajectory tail

Show performance after payment (dotted line continuing beyond payment marker)
If they got paid early and stayed in green = validation
If they got paid early and crashed to red = overpay

Option 4: Reframe the heatmap
The heatmap doesn't show "when payment typically happens" but rather "probability of payment" at each year-performance combination.
So:

High in green zone at Y3 = 80% get paid
High in green zone at Y5 = 90% get paid (more certain)
Payment marker shows they beat the odds (paid at 40% zone) or were obvious (paid at 95% zone)

The Philosophical Question
What's the "norm" you're comparing against?

Descriptive norm: When do QBs at this performance level typically get paid? (neutral)
Prescriptive norm: When should teams pay based on success rates? (evaluative)

If it's descriptive, early payment isn't "bad" - it's just "unusual" or "confident." The outcome determines if it was smart.
Would adding post-payment trajectory solve this? Or do you want the chart to focus purely on the decision moment without outcome evaluation?RetryAI like the trajectory trail option, since determining "success" is very difficultSmart - the trajectory trail lets the data speak without imposing a subjective "success" threshold.
What The Trail Reveals
Post-payment trajectory patterns:

Sustained/improved: Got paid in green, stayed/climbed → justified
Maintained plateau: Got paid in green, flatlined there → reasonable
Regression: Got paid in green, dropped to yellow/red → overpay or injury/decline
Late bloomer vindication: Got paid in yellow (risky), climbed to green → patience rewarded
Gamble failed: Got paid in yellow, stayed/dropped → overpay confirmed

The viewer draws their own conclusions based on what they value (stability vs. upside, risk tolerance, etc.)
Visual Encoding for Pre/Post Payment
Line style differentiation:

Solid line: Pre-payment trajectory (evaluation period)
Dashed/dotted line: Post-payment trajectory (outcome period)
Payment marker: Clear visual break point (maybe a star or dollar sign)

Color consistency:

Keep the same heatmap background throughout
The trajectory line maintains whatever color scheme you're using (if any)
This way you see if they stayed in the same zone or migrated

Practical Boundary Question
How many post-payment years do you show?

2-3 years: Immediate validation of decision
Full contract length: Complete evaluation of deal value
Career end: Ultimate outcome (but gets messy with multiple contracts)

My instinct: Show through Year 5 or 6 regardless of payment timing, so you see 2-3 years post-payment for most QBs. Keeps the time window consistent across all QBs plotted.
Does that feel like enough to evaluate the decision without overcomplicating the viz?RetryAI think maybe 4 years? Too much longer and it might be unwieldy to look at multiple charts (repeated decisions)4 years feels right - it's roughly:

One contract cycle to evaluate
Long enough to see if early promise sustained or hype faded
Short enough to keep charts comparable and scannable

The Multi-Chart Layout
If you're showing multiple QBs for comparison, you'd have:

Small multiples grid: Each QB gets their own chart
Shared heatmap background: Same scale/colors across all charts for direct comparison
Consistent X-axis: Draft year to +4 years
Payment markers: Immediately visible which year they got paid (if at all)

What becomes instantly visible:

QBs who tracked similarly pre-payment but diverged after
QBs paid at similar times but with different trajectory shapes
Outliers who got paid "off-pattern" (early in yellow zone, late despite green zone)

The Repeated Decisions Problem
Some QBs get paid multiple times (2nd contract, then 3rd). Do you:

Show only first payment decision? (cleanest, focuses on rookie→franchise transition)
Show multiple payment markers? (dots at each extension, trail continues)
Separate charts for each contract cycle? ("First Contract Decisions" vs "Second Contract Decisions")

My instinct: First payment only for the main analysis. The rookie deal→second contract decision is the highest-stakes, most uncertain evaluation. Subsequent deals have more data and less variance.
You could do a separate analysis for "who got paid again after their second contract" but that's a different question (sustainability vs. initial evaluation).
Does focusing on that first payment decision feel like the right scope?